{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "  def __init__(self):\n",
    "    super(CustomEnv, self).__init__()\n",
    "    self.action_space = gym.spaces.Box(low=-1, high=1, shape=(5,))\n",
    "    self.observation_space = gym.spaces.Dict(\n",
    "      data=gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 6), dtype=np.float32),\n",
    "      weights=gym.spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
    "    )\n",
    "    # self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(5, 3), dtype=np.float32)\n",
    "  \n",
    "  def reset(self, *args, **kwargs):\n",
    "    x = np.random.rand(4, 6)\n",
    "    x[:, 0] = np.linspace(0, 1, 4)\n",
    "    w0 = np.zeros(5)\n",
    "    w0[-1] = 1.0\n",
    "    return {\n",
    "      'data': x,\n",
    "      'weights': w0\n",
    "    }, {}\n",
    "    # return x, {}\n",
    "  \n",
    "  def step(self, action):\n",
    "    action = (action + 1) / 2\n",
    "    t = np.linspace(0, 1, 5)\n",
    "    t /= t.sum()\n",
    "    reward = -100 * ((action - t)**2).sum()\n",
    "    reward -= (action.sum() - 1)**2\n",
    "\n",
    "    x = np.random.rand(4, 6)\n",
    "    x[:, 0] = np.linspace(0, 1, 4)\n",
    "\n",
    "    finished = reward < -10\n",
    "    finished = False\n",
    "\n",
    "    # print(reward)\n",
    "    return {\n",
    "      'data': x,\n",
    "      'weights': action\n",
    "    }, reward, finished, False, {}\n",
    "    # return x, reward, finished, False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TQC' from 'stable_baselines3' (c:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPG, SAC, TQC, DQN\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NormalActionNoise\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeLimit\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TQC' from 'stable_baselines3' (c:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG, SAC, TQC, DQN\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "train_env = CustomEnv()\n",
    "\n",
    "train_env = TimeLimit(train_env, max_episode_steps=1000)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# train_env.seed(42)\n",
    "train_env.action_space.seed(43)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = SAC('MultiInputPolicy', \n",
    "             train_env, \n",
    "             buffer_size=10**8, \n",
    "             verbose=1, \n",
    "             action_noise=NormalActionNoise(mean=0, sigma=0.02*np.ones(5))\n",
    "            )\n",
    "            #  policy_kwargs={'net_arch': [400, 400],}\n",
    "model.learn(total_timesteps=10**12, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.80157447, 0.6536939 , 0.7087927 , 0.7253792 , 0.9570687 ],\n",
       "       dtype=float32),\n",
       " None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(5, 3)\n",
    "x[:, 0] = np.linspace(0, 1, 5)\n",
    "model.predict({\n",
    "  'data': x.flatten(),\n",
    "  'weights': np.array([0, 0, 0, 0, 1.0])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:605: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 18.80GB > 18.53GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.65e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 1         |\n",
      "|    fps             | 171       |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 1000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 638       |\n",
      "|    critic_loss     | 8.02e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 899       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.05e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 2         |\n",
      "|    fps             | 169       |\n",
      "|    time_elapsed    | 11        |\n",
      "|    total_timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.44e+03  |\n",
      "|    critic_loss     | 3.36e+03  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.66e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 3         |\n",
      "|    fps             | 169       |\n",
      "|    time_elapsed    | 17        |\n",
      "|    total_timesteps | 3000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.3e+03   |\n",
      "|    critic_loss     | 262       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.46e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 23        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.1e+03   |\n",
      "|    critic_loss     | 174       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.34e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 5         |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total_timesteps | 5000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.84e+03  |\n",
      "|    critic_loss     | 485       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.27e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 6         |\n",
      "|    fps             | 169       |\n",
      "|    time_elapsed    | 35        |\n",
      "|    total_timesteps | 6000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.57e+03  |\n",
      "|    critic_loss     | 77.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.21e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 7         |\n",
      "|    fps             | 170       |\n",
      "|    time_elapsed    | 40        |\n",
      "|    total_timesteps | 7000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.25e+03  |\n",
      "|    critic_loss     | 235       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.17e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 8000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.91e+03  |\n",
      "|    critic_loss     | 51.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.14e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 9         |\n",
      "|    fps             | 173       |\n",
      "|    time_elapsed    | 51        |\n",
      "|    total_timesteps | 9000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.53e+03  |\n",
      "|    critic_loss     | 57.7      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.11e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 173       |\n",
      "|    time_elapsed    | 57        |\n",
      "|    total_timesteps | 10000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.13e+03  |\n",
      "|    critic_loss     | 28.7      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.09e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 11        |\n",
      "|    fps             | 174       |\n",
      "|    time_elapsed    | 63        |\n",
      "|    total_timesteps | 11000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.69e+03  |\n",
      "|    critic_loss     | 43.8      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 10899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.07e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 174       |\n",
      "|    time_elapsed    | 68        |\n",
      "|    total_timesteps | 12000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.23e+03  |\n",
      "|    critic_loss     | 17.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 11899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.06e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 13        |\n",
      "|    fps             | 174       |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 13000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.74e+03  |\n",
      "|    critic_loss     | 5.49      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.04e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 14        |\n",
      "|    fps             | 174       |\n",
      "|    time_elapsed    | 80        |\n",
      "|    total_timesteps | 14000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.23e+03  |\n",
      "|    critic_loss     | 12.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 13899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.03e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 15        |\n",
      "|    fps             | 173       |\n",
      "|    time_elapsed    | 86        |\n",
      "|    total_timesteps | 15000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.69e+03  |\n",
      "|    critic_loss     | 19        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.02e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 173       |\n",
      "|    time_elapsed    | 92        |\n",
      "|    total_timesteps | 16000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.01e+04  |\n",
      "|    critic_loss     | 3.31      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.01e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 17        |\n",
      "|    fps             | 173       |\n",
      "|    time_elapsed    | 98        |\n",
      "|    total_timesteps | 17000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.06e+04  |\n",
      "|    critic_loss     | 7.49      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 16899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.01e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 18        |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 104       |\n",
      "|    total_timesteps | 18000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.1e+04   |\n",
      "|    critic_loss     | 8.83      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 17899     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -2e+05   |\n",
      "| time/              |          |\n",
      "|    episodes        | 19       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 19000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.13e+04 |\n",
      "|    critic_loss     | 9.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18899    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.99e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 115       |\n",
      "|    total_timesteps | 20000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.17e+04  |\n",
      "|    critic_loss     | 11.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 19899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.99e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 21        |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 121       |\n",
      "|    total_timesteps | 21000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.2e+04   |\n",
      "|    critic_loss     | 105       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.98e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 22        |\n",
      "|    fps             | 171       |\n",
      "|    time_elapsed    | 128       |\n",
      "|    total_timesteps | 22000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.24e+04  |\n",
      "|    critic_loss     | 6.85      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 21899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.98e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 23        |\n",
      "|    fps             | 169       |\n",
      "|    time_elapsed    | 135       |\n",
      "|    total_timesteps | 23000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.27e+04  |\n",
      "|    critic_loss     | 1.39      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.97e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 142       |\n",
      "|    total_timesteps | 24000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.3e+04   |\n",
      "|    critic_loss     | 44.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 23899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.97e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 25        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 148       |\n",
      "|    total_timesteps | 25000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.32e+04  |\n",
      "|    critic_loss     | 36.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 24899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.97e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 26        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 154       |\n",
      "|    total_timesteps | 26000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.35e+04  |\n",
      "|    critic_loss     | 69.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.96e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 27        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 160       |\n",
      "|    total_timesteps | 27000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.38e+04  |\n",
      "|    critic_loss     | 18.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 26899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.96e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 166       |\n",
      "|    total_timesteps | 28000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.4e+04   |\n",
      "|    critic_loss     | 40.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 27899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.96e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 29        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 172       |\n",
      "|    total_timesteps | 29000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.42e+04  |\n",
      "|    critic_loss     | 18        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.95e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 30        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 178       |\n",
      "|    total_timesteps | 30000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.45e+04  |\n",
      "|    critic_loss     | 8.4       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 29899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.95e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 31        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 184       |\n",
      "|    total_timesteps | 31000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.47e+04  |\n",
      "|    critic_loss     | 55.1      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 30899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.95e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 190       |\n",
      "|    total_timesteps | 32000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.49e+04  |\n",
      "|    critic_loss     | 17.9      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 31899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.95e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 33        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 196       |\n",
      "|    total_timesteps | 33000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.51e+04  |\n",
      "|    critic_loss     | 9.78      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 32899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 34        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 202       |\n",
      "|    total_timesteps | 34000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.52e+04  |\n",
      "|    critic_loss     | 22.8      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 33899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 35        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 208       |\n",
      "|    total_timesteps | 35000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.54e+04  |\n",
      "|    critic_loss     | 23.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 34899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 214       |\n",
      "|    total_timesteps | 36000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.56e+04  |\n",
      "|    critic_loss     | 5.5       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 35899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 37        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 219       |\n",
      "|    total_timesteps | 37000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.57e+04  |\n",
      "|    critic_loss     | 6.93      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 36899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 38        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 225       |\n",
      "|    total_timesteps | 38000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.59e+04  |\n",
      "|    critic_loss     | 8.65      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 37899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.94e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 39        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 231       |\n",
      "|    total_timesteps | 39000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.6e+04   |\n",
      "|    critic_loss     | 0.869     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 237       |\n",
      "|    total_timesteps | 40000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.62e+04  |\n",
      "|    critic_loss     | 44.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 39899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 41        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 243       |\n",
      "|    total_timesteps | 41000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.63e+04  |\n",
      "|    critic_loss     | 16.7      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 40899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 42        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 249       |\n",
      "|    total_timesteps | 42000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.64e+04  |\n",
      "|    critic_loss     | 90        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 41899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 43        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 255       |\n",
      "|    total_timesteps | 43000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.65e+04  |\n",
      "|    critic_loss     | 9.95      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 42899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 261       |\n",
      "|    total_timesteps | 44000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.66e+04  |\n",
      "|    critic_loss     | 45.8      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 43899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 45        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 266       |\n",
      "|    total_timesteps | 45000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.67e+04  |\n",
      "|    critic_loss     | 0.444     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 44899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.93e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 46        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 272       |\n",
      "|    total_timesteps | 46000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.68e+04  |\n",
      "|    critic_loss     | 0.746     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 45899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 47        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 278       |\n",
      "|    total_timesteps | 47000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.69e+04  |\n",
      "|    critic_loss     | 0.564     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 46899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 284       |\n",
      "|    total_timesteps | 48000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.7e+04   |\n",
      "|    critic_loss     | 712       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 47899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 49        |\n",
      "|    fps             | 169       |\n",
      "|    time_elapsed    | 289       |\n",
      "|    total_timesteps | 49000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.71e+04  |\n",
      "|    critic_loss     | 137       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 48899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 50        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 296       |\n",
      "|    total_timesteps | 50000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.72e+04  |\n",
      "|    critic_loss     | 18.6      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 49899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 51        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 303       |\n",
      "|    total_timesteps | 51000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.73e+04  |\n",
      "|    critic_loss     | 8.45      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 50899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 309       |\n",
      "|    total_timesteps | 52000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.73e+04  |\n",
      "|    critic_loss     | 55        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 51899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 53        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 315       |\n",
      "|    total_timesteps | 53000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.74e+04  |\n",
      "|    critic_loss     | 32.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 52899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 54        |\n",
      "|    fps             | 168       |\n",
      "|    time_elapsed    | 321       |\n",
      "|    total_timesteps | 54000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.75e+04  |\n",
      "|    critic_loss     | 25.5      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 53899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 55        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 327       |\n",
      "|    total_timesteps | 55000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.75e+04  |\n",
      "|    critic_loss     | 48.6      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 54899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 333       |\n",
      "|    total_timesteps | 56000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.76e+04  |\n",
      "|    critic_loss     | 15.7      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 55899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 57        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 339       |\n",
      "|    total_timesteps | 57000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.76e+04  |\n",
      "|    critic_loss     | 3.69      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 56899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 58        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 345       |\n",
      "|    total_timesteps | 58000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.77e+04  |\n",
      "|    critic_loss     | 15        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 57899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 59        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 351       |\n",
      "|    total_timesteps | 59000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.77e+04  |\n",
      "|    critic_loss     | 89.3      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 58899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 357       |\n",
      "|    total_timesteps | 60000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.78e+04  |\n",
      "|    critic_loss     | 80.7      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 59899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 61        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 363       |\n",
      "|    total_timesteps | 61000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.79e+04  |\n",
      "|    critic_loss     | 3.73      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 60899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 62        |\n",
      "|    fps             | 167       |\n",
      "|    time_elapsed    | 369       |\n",
      "|    total_timesteps | 62000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.79e+04  |\n",
      "|    critic_loss     | 0.855     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 61899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 63        |\n",
      "|    fps             | 166       |\n",
      "|    time_elapsed    | 377       |\n",
      "|    total_timesteps | 63000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.79e+04  |\n",
      "|    critic_loss     | 8.16      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 62899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 166       |\n",
      "|    time_elapsed    | 384       |\n",
      "|    total_timesteps | 64000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.8e+04   |\n",
      "|    critic_loss     | 2.19      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 63899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.91e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 65        |\n",
      "|    fps             | 165       |\n",
      "|    time_elapsed    | 391       |\n",
      "|    total_timesteps | 65000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.8e+04   |\n",
      "|    critic_loss     | 43        |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 64899     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     18\u001b[0m              train_env, \n\u001b[0;32m     19\u001b[0m              buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m, \n\u001b[0;32m     20\u001b[0m              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m             )\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;66;03m#  policy_kwargs={'net_arch': [400, 400],}\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:200\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    199\u001b[0m actor_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m polyak_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau)\n\u001b[0;32m    203\u001b[0m polyak_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:523\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    520\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n\u001b[1;32m--> 523\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_addcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# Delete the local intermediate since it won't be used anymore to save on peak memory\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m device_grads\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG, SAC, DQN\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "train_env = CustomEnv()\n",
    "\n",
    "train_env = TimeLimit(train_env, max_episode_steps=1000)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# train_env.seed(42)\n",
    "train_env.action_space.seed(43)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = DDPG('MultiInputPolicy', \n",
    "             train_env, \n",
    "             buffer_size=10**8, \n",
    "             verbose=1,\n",
    "            )\n",
    "            #  policy_kwargs={'net_arch': [400, 400],}\n",
    "model.learn(total_timesteps=10**12, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1.], dtype=float32), None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(5, 3)\n",
    "x[:, 0] = np.linspace(0, 1, 5)\n",
    "model.predict({\n",
    "  'data': x.flatten(),\n",
    "  'weights': np.array([0, 0, 0, 0, 1.0])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:605: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 18.80GB > 18.11GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 1         |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 6         |\n",
      "|    total_timesteps | 1000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 44.1      |\n",
      "|    critic_loss     | 4.3       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 899       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.21e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 2         |\n",
      "|    fps             | 145       |\n",
      "|    time_elapsed    | 13        |\n",
      "|    total_timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 42.5      |\n",
      "|    critic_loss     | 0.902     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -8.15e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 3         |\n",
      "|    fps             | 148       |\n",
      "|    time_elapsed    | 20        |\n",
      "|    total_timesteps | 3000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 40.9      |\n",
      "|    critic_loss     | 0.316     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -6.16e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 150       |\n",
      "|    time_elapsed    | 26        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 39.2      |\n",
      "|    critic_loss     | 0.13      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.96e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 5         |\n",
      "|    fps             | 151       |\n",
      "|    time_elapsed    | 32        |\n",
      "|    total_timesteps | 5000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37.6      |\n",
      "|    critic_loss     | 0.0896    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.15e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 6         |\n",
      "|    fps             | 152       |\n",
      "|    time_elapsed    | 39        |\n",
      "|    total_timesteps | 6000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 35.6      |\n",
      "|    critic_loss     | 0.0339    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.57e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 7         |\n",
      "|    fps             | 153       |\n",
      "|    time_elapsed    | 45        |\n",
      "|    total_timesteps | 7000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 33.9      |\n",
      "|    critic_loss     | 0.0247    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.14e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 154       |\n",
      "|    time_elapsed    | 51        |\n",
      "|    total_timesteps | 8000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 32.2      |\n",
      "|    critic_loss     | 0.0322    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -2.8e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 9        |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 30.7     |\n",
      "|    critic_loss     | 0.0142   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8899     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.53e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 152       |\n",
      "|    time_elapsed    | 65        |\n",
      "|    total_timesteps | 10000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 29        |\n",
      "|    critic_loss     | 0.0103    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -2.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 11       |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 27.6     |\n",
      "|    critic_loss     | 0.0265   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10899    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.12e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 149       |\n",
      "|    time_elapsed    | 80        |\n",
      "|    total_timesteps | 12000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 26.1      |\n",
      "|    critic_loss     | 0.0183    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 11899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.96e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 13        |\n",
      "|    fps             | 147       |\n",
      "|    time_elapsed    | 88        |\n",
      "|    total_timesteps | 13000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.7      |\n",
      "|    critic_loss     | 0.0112    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.83e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 14        |\n",
      "|    fps             | 147       |\n",
      "|    time_elapsed    | 95        |\n",
      "|    total_timesteps | 14000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23.5      |\n",
      "|    critic_loss     | 0.011     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 13899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.71e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 15        |\n",
      "|    fps             | 147       |\n",
      "|    time_elapsed    | 102       |\n",
      "|    total_timesteps | 15000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 22.2      |\n",
      "|    critic_loss     | 0.0155    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.61e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 111       |\n",
      "|    total_timesteps | 16000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 21.1      |\n",
      "|    critic_loss     | 0.0144    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.51e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 17        |\n",
      "|    fps             | 142       |\n",
      "|    time_elapsed    | 119       |\n",
      "|    total_timesteps | 17000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 19.9      |\n",
      "|    critic_loss     | 0.0157    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 16899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.43e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 18        |\n",
      "|    fps             | 142       |\n",
      "|    time_elapsed    | 126       |\n",
      "|    total_timesteps | 18000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 19        |\n",
      "|    critic_loss     | 0.00816   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 17899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.36e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 19        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 132       |\n",
      "|    total_timesteps | 19000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17.9      |\n",
      "|    critic_loss     | 0.015     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18899     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -1.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 17.2     |\n",
      "|    critic_loss     | 0.0139   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.24e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 21        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 146       |\n",
      "|    total_timesteps | 21000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 16.2      |\n",
      "|    critic_loss     | 0.0111    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.19e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 22        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 153       |\n",
      "|    total_timesteps | 22000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15.4      |\n",
      "|    critic_loss     | 0.00959   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 21899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.14e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 23        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 160       |\n",
      "|    total_timesteps | 23000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14.7      |\n",
      "|    critic_loss     | 0.0437    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.09e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 143       |\n",
      "|    time_elapsed    | 166       |\n",
      "|    total_timesteps | 24000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 14        |\n",
      "|    critic_loss     | 0.0041    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 23899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.05e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 25        |\n",
      "|    fps             | 142       |\n",
      "|    time_elapsed    | 175       |\n",
      "|    total_timesteps | 25000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 13.3      |\n",
      "|    critic_loss     | 0.00978   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 24899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 26        |\n",
      "|    fps             | 141       |\n",
      "|    time_elapsed    | 183       |\n",
      "|    total_timesteps | 26000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 12.5      |\n",
      "|    critic_loss     | 0.0862    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25899     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -978     |\n",
      "| time/              |          |\n",
      "|    episodes        | 27       |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 190      |\n",
      "|    total_timesteps | 27000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 12       |\n",
      "|    critic_loss     | 0.00393  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -946     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 11.5     |\n",
      "|    critic_loss     | 0.0043   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -915     |\n",
      "| time/              |          |\n",
      "|    episodes        | 29       |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 29000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 10.9     |\n",
      "|    critic_loss     | 0.00514  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -887     |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 214      |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 10.4     |\n",
      "|    critic_loss     | 0.0145   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -860     |\n",
      "| time/              |          |\n",
      "|    episodes        | 31       |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 31000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 9.76     |\n",
      "|    critic_loss     | 0.174    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -835     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 9.42     |\n",
      "|    critic_loss     | 0.00619  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -812     |\n",
      "| time/              |          |\n",
      "|    episodes        | 33       |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 33000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.89     |\n",
      "|    critic_loss     | 0.0226   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -790     |\n",
      "| time/              |          |\n",
      "|    episodes        | 34       |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 34000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.46     |\n",
      "|    critic_loss     | 0.0126   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -769     |\n",
      "| time/              |          |\n",
      "|    episodes        | 35       |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 250      |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.05     |\n",
      "|    critic_loss     | 0.205    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -750     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.62     |\n",
      "|    critic_loss     | 0.0029   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -731     |\n",
      "| time/              |          |\n",
      "|    episodes        | 37       |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 37000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.25     |\n",
      "|    critic_loss     | 0.00186  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -713     |\n",
      "| time/              |          |\n",
      "|    episodes        | 38       |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 266      |\n",
      "|    total_timesteps | 38000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.8      |\n",
      "|    critic_loss     | 0.00636  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -696     |\n",
      "| time/              |          |\n",
      "|    episodes        | 39       |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 272      |\n",
      "|    total_timesteps | 39000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.52     |\n",
      "|    critic_loss     | 0.0015   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -680     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.27     |\n",
      "|    critic_loss     | 0.00331  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -665     |\n",
      "| time/              |          |\n",
      "|    episodes        | 41       |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 41000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.92     |\n",
      "|    critic_loss     | 0.181    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40899    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     18\u001b[0m              train_env, \n\u001b[0;32m     19\u001b[0m              buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m, \n\u001b[0;32m     20\u001b[0m              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m              action_noise\u001b[38;5;241m=\u001b[39mNormalActionNoise(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     22\u001b[0m             )\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;66;03m#  policy_kwargs={'net_arch': [400, 400],}\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:194\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_delay \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# Compute actor loss\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m     actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mq1_forward(replay_data\u001b[38;5;241m.\u001b[39mobservations, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    195\u001b[0m     actor_losses\u001b[38;5;241m.\u001b[39mappend(actor_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# Optimize the actor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\policies.py:78\u001b[0m, in \u001b[0;36mActor.forward\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# assert deterministic, 'The TD3 actor only outputs deterministic actions'\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_extractor)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG, SAC, DQN\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "train_env = CustomEnv()\n",
    "\n",
    "train_env = TimeLimit(train_env, max_episode_steps=1000)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# train_env.seed(42)\n",
    "train_env.action_space.seed(43)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = DDPG('MultiInputPolicy', \n",
    "             train_env, \n",
    "             buffer_size=10**8, \n",
    "             verbose=1,\n",
    "             action_noise=NormalActionNoise(mean=0, sigma=0.02*np.ones(5))\n",
    "            )\n",
    "            #  policy_kwargs={'net_arch': [400, 400],}\n",
    "model.learn(total_timesteps=10**12, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1920929e-07, 2.6921946e-01, 5.1675427e-01, 7.3541683e-01,\n",
       "       1.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(5, 3)\n",
    "x[:, 0] = np.linspace(0, 1, 5)\n",
    "a = model.predict({\n",
    "  'data': x.flatten(),\n",
    "  'weights': np.array([0, 0, 0, 0, 1.0])\n",
    "})[0]\n",
    "(a + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "# class Custom_EIEE_CNN_Extractor(BaseFeaturesExtractor):\n",
    "#     def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 21):\n",
    "#         super(Custom_EIEE_CNN_Extractor, self).__init__(observation_space, features_dim)\n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv2d(1, 2, kernel_size=(1, 4)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(2, 4, kernel_size=(1, 3)),\n",
    "#         ).cuda()\n",
    "\n",
    "#     def forward(self, observations: dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "#         data = observations['data']\n",
    "#         if len(data.shape) == 2:\n",
    "#             data = data[:, None, None, :]\n",
    "#         else:\n",
    "#             data = data[:, None, :, :]\n",
    "#         # print(f\"{data.shape=}\")\n",
    "#         x = self.cnn(data)\n",
    "#         w = observations['weights'][:, None, :, None]\n",
    "#         # print(f\"{x.shape=}, {w.shape=}\")\n",
    "#         return torch.cat((x.flatten(start_dim=1), observations['weights'].flatten(start_dim=1)), dim=1)\n",
    "#         y = torch.cat((x, w), dim=1).flatten(start_dim=1)\n",
    "#         # print(f\"{y.shape=}\")\n",
    "#         return y\n",
    "\n",
    "\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class Custom_EIEE_CNN_Extractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 37):\n",
    "        super(Custom_EIEE_CNN_Extractor, self).__init__(observation_space, features_dim)\n",
    "        self.universe_size, data_len = observation_space['data'].shape\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=(1, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 4, kernel_size=(1, 3))\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, observations: dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        # print(f\"{observations['data'][:, None, :, :].shape=}\")\n",
    "        x = self.cnn(observations['data'][:, None, :, :])\n",
    "        # print(f\"post cnn {x.shape=}, {observations['weights'].shape=}\")\n",
    "        # x = torch.hstack([x.flatten(start_dim=1), observations['weights']])\n",
    "        # return x.flatten(start_dim=1)\n",
    "        # print(f\"{x.flatten(start_dim=1).shape=}, {observations['weights'].flatten(start_dim=1).shape=}\")\n",
    "        return torch.cat((x.flatten(start_dim=1), observations['weights'].flatten(start_dim=1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1        |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 27.8     |\n",
      "|    critic_loss     | 4.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 899      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 2         |\n",
      "|    fps             | 91        |\n",
      "|    time_elapsed    | 21        |\n",
      "|    total_timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 29.8      |\n",
      "|    critic_loss     | 0.348     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -8e+03   |\n",
      "| time/              |          |\n",
      "|    episodes        | 3        |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 32.1     |\n",
      "|    critic_loss     | 0.097    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2899     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -6.07e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 44        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 30.6      |\n",
      "|    critic_loss     | 0.118     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.88e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 5         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 55        |\n",
      "|    total_timesteps | 5000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 28.9      |\n",
      "|    critic_loss     | 0.0572    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.08e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 6         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 66        |\n",
      "|    total_timesteps | 6000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 27.1      |\n",
      "|    critic_loss     | 0.0203    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.51e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 7         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 77        |\n",
      "|    total_timesteps | 7000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 25.3      |\n",
      "|    critic_loss     | 0.016     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.08e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 88        |\n",
      "|    total_timesteps | 8000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.1      |\n",
      "|    critic_loss     | 0.0153    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.74e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 9         |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 99        |\n",
      "|    total_timesteps | 9000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23        |\n",
      "|    critic_loss     | 0.0243    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.48e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 110       |\n",
      "|    total_timesteps | 10000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 21.8      |\n",
      "|    critic_loss     | 0.0196    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.26e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 11        |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 121       |\n",
      "|    total_timesteps | 11000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 20.6      |\n",
      "|    critic_loss     | 0.0054    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 10899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.07e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 132       |\n",
      "|    total_timesteps | 12000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 19.4      |\n",
      "|    critic_loss     | 0.0576    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 11899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.92e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 13        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 144       |\n",
      "|    total_timesteps | 13000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 18.5      |\n",
      "|    critic_loss     | 0.0522    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.79e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 14        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 156       |\n",
      "|    total_timesteps | 14000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17.5      |\n",
      "|    critic_loss     | 0.00201   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 13899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.67e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 15        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 15000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 16.7      |\n",
      "|    critic_loss     | 0.0284    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.57e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 178       |\n",
      "|    total_timesteps | 16000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15.8      |\n",
      "|    critic_loss     | 0.0106    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.48e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 17        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 190       |\n",
      "|    total_timesteps | 17000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 15        |\n",
      "|    critic_loss     | 0.0119    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 16899     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 18       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 14.3     |\n",
      "|    critic_loss     | 0.00759  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.33e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 19        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 212       |\n",
      "|    total_timesteps | 19000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 13.6      |\n",
      "|    critic_loss     | 0.0187    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 223       |\n",
      "|    total_timesteps | 20000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 12.6      |\n",
      "|    critic_loss     | 0.00669   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 19899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.21e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 21        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 236       |\n",
      "|    total_timesteps | 21000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 11.9      |\n",
      "|    critic_loss     | 0.0156    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.16e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 22        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 248       |\n",
      "|    total_timesteps | 22000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 11.3      |\n",
      "|    critic_loss     | 0.0125    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 21899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.11e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 23        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 259       |\n",
      "|    total_timesteps | 23000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 10.8      |\n",
      "|    critic_loss     | 0.00958   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.07e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 271       |\n",
      "|    total_timesteps | 24000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 10.2      |\n",
      "|    critic_loss     | 0.0122    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 23899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.03e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 25        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 282       |\n",
      "|    total_timesteps | 25000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.52      |\n",
      "|    critic_loss     | 0.00704   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 24899     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -994     |\n",
      "| time/              |          |\n",
      "|    episodes        | 26       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 26000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 9.06     |\n",
      "|    critic_loss     | 0.0174   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -959     |\n",
      "| time/              |          |\n",
      "|    episodes        | 27       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 27000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.48     |\n",
      "|    critic_loss     | 0.00696  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -927     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.11     |\n",
      "|    critic_loss     | 0.0231   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -898     |\n",
      "| time/              |          |\n",
      "|    episodes        | 29       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 29000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.47     |\n",
      "|    critic_loss     | 0.00714  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -870     |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 337      |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 7.2      |\n",
      "|    critic_loss     | 0.00407  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -844     |\n",
      "| time/              |          |\n",
      "|    episodes        | 31       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 31000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.85     |\n",
      "|    critic_loss     | 0.0105   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -819     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.52     |\n",
      "|    critic_loss     | 0.0177   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -796     |\n",
      "| time/              |          |\n",
      "|    episodes        | 33       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 372      |\n",
      "|    total_timesteps | 33000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.25     |\n",
      "|    critic_loss     | 0.0089   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -775     |\n",
      "| time/              |          |\n",
      "|    episodes        | 34       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 383      |\n",
      "|    total_timesteps | 34000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.89     |\n",
      "|    critic_loss     | 0.0232   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -755     |\n",
      "| time/              |          |\n",
      "|    episodes        | 35       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 395      |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.61     |\n",
      "|    critic_loss     | 0.00449  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -736     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 406      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.35     |\n",
      "|    critic_loss     | 0.00283  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -718     |\n",
      "| time/              |          |\n",
      "|    episodes        | 37       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 417      |\n",
      "|    total_timesteps | 37000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.95     |\n",
      "|    critic_loss     | 0.0188   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -702     |\n",
      "| time/              |          |\n",
      "|    episodes        | 38       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 428      |\n",
      "|    total_timesteps | 38000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.65     |\n",
      "|    critic_loss     | 0.00282  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -686     |\n",
      "| time/              |          |\n",
      "|    episodes        | 39       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 439      |\n",
      "|    total_timesteps | 39000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.43     |\n",
      "|    critic_loss     | 0.0122   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -671     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 450      |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.16     |\n",
      "|    critic_loss     | 0.0765   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -656     |\n",
      "| time/              |          |\n",
      "|    episodes        | 41       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 462      |\n",
      "|    total_timesteps | 41000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.9      |\n",
      "|    critic_loss     | 0.00459  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -642     |\n",
      "| time/              |          |\n",
      "|    episodes        | 42       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 473      |\n",
      "|    total_timesteps | 42000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.69     |\n",
      "|    critic_loss     | 0.0024   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -629     |\n",
      "| time/              |          |\n",
      "|    episodes        | 43       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 43000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.45     |\n",
      "|    critic_loss     | 0.00862  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 42899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -617     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 496      |\n",
      "|    total_timesteps | 44000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.98     |\n",
      "|    critic_loss     | 0.00293  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -605     |\n",
      "| time/              |          |\n",
      "|    episodes        | 45       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 507      |\n",
      "|    total_timesteps | 45000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.7      |\n",
      "|    critic_loss     | 0.00309  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -593     |\n",
      "| time/              |          |\n",
      "|    episodes        | 46       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 518      |\n",
      "|    total_timesteps | 46000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.52     |\n",
      "|    critic_loss     | 0.00135  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -582     |\n",
      "| time/              |          |\n",
      "|    episodes        | 47       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 529      |\n",
      "|    total_timesteps | 47000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.46     |\n",
      "|    critic_loss     | 0.00541  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -573     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 541      |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.07     |\n",
      "|    critic_loss     | 0.00631  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -562     |\n",
      "| time/              |          |\n",
      "|    episodes        | 49       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 552      |\n",
      "|    total_timesteps | 49000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.87     |\n",
      "|    critic_loss     | 0.00319  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -552     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 563      |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.72     |\n",
      "|    critic_loss     | 0.00218  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 49899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -543     |\n",
      "| time/              |          |\n",
      "|    episodes        | 51       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 51000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.61     |\n",
      "|    critic_loss     | 0.00348  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -534     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 586      |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.47     |\n",
      "|    critic_loss     | 0.0049   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -525     |\n",
      "| time/              |          |\n",
      "|    episodes        | 53       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 597      |\n",
      "|    total_timesteps | 53000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.41     |\n",
      "|    critic_loss     | 0.0123   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 52899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -516     |\n",
      "| time/              |          |\n",
      "|    episodes        | 54       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.4      |\n",
      "|    critic_loss     | 0.00484  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -508     |\n",
      "| time/              |          |\n",
      "|    episodes        | 55       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 619      |\n",
      "|    total_timesteps | 55000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.37     |\n",
      "|    critic_loss     | 0.00925  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 54899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -501     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 630      |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.38     |\n",
      "|    critic_loss     | 0.0823   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 55899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    episodes        | 57       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 641      |\n",
      "|    total_timesteps | 57000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.42     |\n",
      "|    critic_loss     | 0.0123   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 56899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -486     |\n",
      "| time/              |          |\n",
      "|    episodes        | 58       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 652      |\n",
      "|    total_timesteps | 58000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.45     |\n",
      "|    critic_loss     | 0.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 57899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -479     |\n",
      "| time/              |          |\n",
      "|    episodes        | 59       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 663      |\n",
      "|    total_timesteps | 59000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.61     |\n",
      "|    critic_loss     | 0.00398  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 58899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -472     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 675      |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.64     |\n",
      "|    critic_loss     | 0.00243  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 59899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -465     |\n",
      "| time/              |          |\n",
      "|    episodes        | 61       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 686      |\n",
      "|    total_timesteps | 61000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.79     |\n",
      "|    critic_loss     | 0.00205  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 60899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -459     |\n",
      "| time/              |          |\n",
      "|    episodes        | 62       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 697      |\n",
      "|    total_timesteps | 62000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.92     |\n",
      "|    critic_loss     | 0.00319  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 61899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -453     |\n",
      "| time/              |          |\n",
      "|    episodes        | 63       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 707      |\n",
      "|    total_timesteps | 63000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.04     |\n",
      "|    critic_loss     | 0.0966   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 62899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -447     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 718      |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1      |\n",
      "|    critic_loss     | 0.00208  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 63899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -441     |\n",
      "| time/              |          |\n",
      "|    episodes        | 65       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 730      |\n",
      "|    total_timesteps | 65000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.18     |\n",
      "|    critic_loss     | 0.000822 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 64899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -435     |\n",
      "| time/              |          |\n",
      "|    episodes        | 66       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 741      |\n",
      "|    total_timesteps | 66000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.28     |\n",
      "|    critic_loss     | 0.0109   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 65899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -430     |\n",
      "| time/              |          |\n",
      "|    episodes        | 67       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 752      |\n",
      "|    total_timesteps | 67000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.35     |\n",
      "|    critic_loss     | 0.0266   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 66899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -426     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 763      |\n",
      "|    total_timesteps | 68000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.47     |\n",
      "|    critic_loss     | 0.00508  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 67899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -421     |\n",
      "| time/              |          |\n",
      "|    episodes        | 69       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 775      |\n",
      "|    total_timesteps | 69000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.55     |\n",
      "|    critic_loss     | 0.00177  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 68899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -416     |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 786      |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.63     |\n",
      "|    critic_loss     | 0.00271  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 69899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -411     |\n",
      "| time/              |          |\n",
      "|    episodes        | 71       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 797      |\n",
      "|    total_timesteps | 71000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.7      |\n",
      "|    critic_loss     | 0.0632   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 70899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -406     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 809      |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.72     |\n",
      "|    critic_loss     | 0.001    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 71899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -401     |\n",
      "| time/              |          |\n",
      "|    episodes        | 73       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 819      |\n",
      "|    total_timesteps | 73000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.82     |\n",
      "|    critic_loss     | 0.00978  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 72899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -397     |\n",
      "| time/              |          |\n",
      "|    episodes        | 74       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 831      |\n",
      "|    total_timesteps | 74000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.92     |\n",
      "|    critic_loss     | 0.00436  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 73899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -392     |\n",
      "| time/              |          |\n",
      "|    episodes        | 75       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 842      |\n",
      "|    total_timesteps | 75000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.98     |\n",
      "|    critic_loss     | 0.0496   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 74899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -388     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 853      |\n",
      "|    total_timesteps | 76000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.98     |\n",
      "|    critic_loss     | 0.00102  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 75899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -384     |\n",
      "| time/              |          |\n",
      "|    episodes        | 77       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 865      |\n",
      "|    total_timesteps | 77000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.06     |\n",
      "|    critic_loss     | 0.0134   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 76899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -380     |\n",
      "| time/              |          |\n",
      "|    episodes        | 78       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 876      |\n",
      "|    total_timesteps | 78000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.2      |\n",
      "|    critic_loss     | 0.00617  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 77899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -376     |\n",
      "| time/              |          |\n",
      "|    episodes        | 79       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 887      |\n",
      "|    total_timesteps | 79000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.15     |\n",
      "|    critic_loss     | 0.000805 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 78899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -373     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 898      |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.11     |\n",
      "|    critic_loss     | 0.00164  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 79899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -369     |\n",
      "| time/              |          |\n",
      "|    episodes        | 81       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 909      |\n",
      "|    total_timesteps | 81000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.24     |\n",
      "|    critic_loss     | 0.00605  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 80899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -365     |\n",
      "| time/              |          |\n",
      "|    episodes        | 82       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 920      |\n",
      "|    total_timesteps | 82000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.21     |\n",
      "|    critic_loss     | 0.00346  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 81899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -361     |\n",
      "| time/              |          |\n",
      "|    episodes        | 83       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 931      |\n",
      "|    total_timesteps | 83000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.29     |\n",
      "|    critic_loss     | 0.00191  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 82899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -358     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 942      |\n",
      "|    total_timesteps | 84000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.28     |\n",
      "|    critic_loss     | 0.000637 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 83899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -354     |\n",
      "| time/              |          |\n",
      "|    episodes        | 85       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 953      |\n",
      "|    total_timesteps | 85000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.32     |\n",
      "|    critic_loss     | 0.00101  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 84899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -351     |\n",
      "| time/              |          |\n",
      "|    episodes        | 86       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 964      |\n",
      "|    total_timesteps | 86000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.4      |\n",
      "|    critic_loss     | 0.139    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 85899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -348     |\n",
      "| time/              |          |\n",
      "|    episodes        | 87       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 976      |\n",
      "|    total_timesteps | 87000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.42     |\n",
      "|    critic_loss     | 0.000744 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 86899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -344     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 987      |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.53     |\n",
      "|    critic_loss     | 0.00883  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 87899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -341     |\n",
      "| time/              |          |\n",
      "|    episodes        | 89       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 998      |\n",
      "|    total_timesteps | 89000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.55     |\n",
      "|    critic_loss     | 0.00781  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 88899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -338     |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1009     |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.54     |\n",
      "|    critic_loss     | 0.075    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 89899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -335     |\n",
      "| time/              |          |\n",
      "|    episodes        | 91       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1020     |\n",
      "|    total_timesteps | 91000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.58     |\n",
      "|    critic_loss     | 0.00268  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 90899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -332     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1031     |\n",
      "|    total_timesteps | 92000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.59     |\n",
      "|    critic_loss     | 0.00212  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 91899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -329     |\n",
      "| time/              |          |\n",
      "|    episodes        | 93       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1042     |\n",
      "|    total_timesteps | 93000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.64     |\n",
      "|    critic_loss     | 0.00131  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 92899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -327     |\n",
      "| time/              |          |\n",
      "|    episodes        | 94       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1053     |\n",
      "|    total_timesteps | 94000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.75     |\n",
      "|    critic_loss     | 0.0035   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 93899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -324     |\n",
      "| time/              |          |\n",
      "|    episodes        | 95       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1064     |\n",
      "|    total_timesteps | 95000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.77     |\n",
      "|    critic_loss     | 0.00421  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 94899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -321     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1075     |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.77     |\n",
      "|    critic_loss     | 0.00304  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 95899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -318     |\n",
      "| time/              |          |\n",
      "|    episodes        | 97       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1086     |\n",
      "|    total_timesteps | 97000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.82     |\n",
      "|    critic_loss     | 0.0284   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 96899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -316     |\n",
      "| time/              |          |\n",
      "|    episodes        | 98       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1097     |\n",
      "|    total_timesteps | 98000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.73     |\n",
      "|    critic_loss     | 0.00182  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 97899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -313     |\n",
      "| time/              |          |\n",
      "|    episodes        | 99       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1108     |\n",
      "|    total_timesteps | 99000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.84     |\n",
      "|    critic_loss     | 0.00717  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 98899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -311     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1119     |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.79     |\n",
      "|    critic_loss     | 0.00361  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 99899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -91.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 101      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1131     |\n",
      "|    total_timesteps | 101000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.76     |\n",
      "|    critic_loss     | 0.00353  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 100899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -80.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 102      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1142     |\n",
      "|    total_timesteps | 102000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.72     |\n",
      "|    critic_loss     | 0.00631  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 101899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -72.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 103      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1153     |\n",
      "|    total_timesteps | 103000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.7      |\n",
      "|    critic_loss     | 0.00479  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 102899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -70.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 1163     |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.57     |\n",
      "|    critic_loss     | 0.0964   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 103899   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG, SAC, DQN\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "train_env = CustomEnv()\n",
    "\n",
    "train_env = TimeLimit(train_env, max_episode_steps=1000)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# train_env.seed(42)\n",
    "train_env.action_space.seed(43)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = DDPG(\n",
    "  'MultiInputPolicy', \n",
    "  train_env, \n",
    "  buffer_size=10**6, \n",
    "  verbose=1,\n",
    "  action_noise=NormalActionNoise(mean=0, sigma=0.02*np.ones(5)),\n",
    "  policy_kwargs={\n",
    "    'features_extractor_class': Custom_EIEE_CNN_Extractor\n",
    "  }\n",
    ")\n",
    "model.learn(total_timesteps=10**12, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1        |\n",
      "|    fps             | 123      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 27.8     |\n",
      "|    critic_loss     | 4.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 899      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 2         |\n",
      "|    fps             | 111       |\n",
      "|    time_elapsed    | 17        |\n",
      "|    total_timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 29.7      |\n",
      "|    critic_loss     | 0.351     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -8e+03   |\n",
      "| time/              |          |\n",
      "|    episodes        | 3        |\n",
      "|    fps             | 101      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 32.1     |\n",
      "|    critic_loss     | 0.0983   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2899     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -6.09e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 98        |\n",
      "|    time_elapsed    | 40        |\n",
      "|    total_timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 30.9      |\n",
      "|    critic_loss     | 0.117     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -4.9e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 5        |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 29.2     |\n",
      "|    critic_loss     | 0.0564   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.09e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 6         |\n",
      "|    fps             | 91        |\n",
      "|    time_elapsed    | 65        |\n",
      "|    total_timesteps | 6000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 27.4      |\n",
      "|    critic_loss     | 0.0212    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.52e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 7         |\n",
      "|    fps             | 92        |\n",
      "|    time_elapsed    | 75        |\n",
      "|    total_timesteps | 7000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 25.6      |\n",
      "|    critic_loss     | 0.0187    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.09e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 92        |\n",
      "|    time_elapsed    | 86        |\n",
      "|    total_timesteps | 8000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 24.3      |\n",
      "|    critic_loss     | 0.0165    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.75e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 9         |\n",
      "|    fps             | 91        |\n",
      "|    time_elapsed    | 97        |\n",
      "|    total_timesteps | 9000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23.2      |\n",
      "|    critic_loss     | 0.0234    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 8899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.49e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 90        |\n",
      "|    time_elapsed    | 110       |\n",
      "|    total_timesteps | 10000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 22.1      |\n",
      "|    critic_loss     | 0.00875   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9899      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 11        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 124       |\n",
      "|    total_timesteps | 11000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 21        |\n",
      "|    critic_loss     | 0.0127    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 10899     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.08e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 135       |\n",
      "|    total_timesteps | 12000     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 19.8      |\n",
      "|    critic_loss     | 0.0459    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 11899     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 27\u001b[0m\n\u001b[0;32m     15\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     19\u001b[0m   train_env, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m   }\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\td3\\td3.py:174\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    171\u001b[0m next_actions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target(replay_data\u001b[38;5;241m.\u001b[39mnext_observations) \u001b[38;5;241m+\u001b[39m noise)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Compute the next Q-values: min over all critics targets\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_observations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_actions\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    175\u001b[0m next_q_values, _ \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mmin(next_q_values, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m target_q_values \u001b[38;5;241m=\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m replay_data\u001b[38;5;241m.\u001b[39mdones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:975\u001b[0m, in \u001b[0;36mContinuousCritic.forward\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: th\u001b[38;5;241m.\u001b[39mTensor, actions: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;66;03m# Learn the features extractor using the policy loss only\u001b[39;00m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# when the features_extractor is shared with the actor\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor):\n\u001b[1;32m--> 975\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m     qvalue_input \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([features, actions], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(q_net(qvalue_input) \u001b[38;5;28;01mfor\u001b[39;00m q_net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_networks)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[1;34m(self, obs, features_extractor)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 42\u001b[0m, in \u001b[0;36mCustom_EIEE_CNN_Extractor.forward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# print(f\"{observations['data'][:, None, :, :].shape=}\")\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# print(f\"post cnn {x.shape=}, {observations['weights'].shape=}\")\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# x = torch.hstack([x.flatten(start_dim=1), observations['weights']])\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# return x.flatten(start_dim=1)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# print(f\"{x.flatten(start_dim=1).shape=}, {observations['weights'].flatten(start_dim=1).shape=}\")\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((x\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), observations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sumit\\GitRepos\\portfolio-rl\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG, SAC, DQN\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "train_env = CustomEnv()\n",
    "\n",
    "train_env = TimeLimit(train_env, max_episode_steps=1000)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# train_env.seed(42)\n",
    "train_env.action_space.seed(43)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = DDPG(\n",
    "  'MultiInputPolicy', \n",
    "  train_env, \n",
    "  buffer_size=10**6, \n",
    "  verbose=1,\n",
    "  action_noise=NormalActionNoise(mean=0, sigma=0.02*np.ones(5)),\n",
    "  policy_kwargs={\n",
    "    'features_extractor_class': Custom_EIEE_CNN_Extractor\n",
    "  }\n",
    ")\n",
    "model.learn(total_timesteps=10**12, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
